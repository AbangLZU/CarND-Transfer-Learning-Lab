{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning with VGG, Inception and ResNet\n",
    "\n",
    "In this lab, you will continue exploring transfer learning. You've already explored feature extraction with Alexnet and TensorFlow. Next, you will use Keras to explore feature extraction with the VGG, Inception and ResNet architectures. The models you will use were trained for days or weeks on the [ImageNet dataset](http://www.image-net.org/). Thus, the weights escapsulate higher-level features learned from thousands of classes.\n",
    "\n",
    "We'll use two datasets in this lab:\n",
    "\n",
    "1. [German Traffic Sign Dataset](http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset)\n",
    "2. [Cifar10](https://www.cs.toronto.edu/~kriz/cifar.html)\n",
    "\n",
    "How will the pretrained model perform on the new datasets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense, Flatten, Input\n",
    "from keras.models import Model\n",
    "from keras.datasets import cifar10\n",
    "from skimage.transform import resize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data functions\n",
    "traffic_training_file = ''\n",
    "traffic_testing_file = ''\n",
    "\n",
    "def load_traffic():\n",
    "    with open(traffic_training_file, mode='rb') as f:\n",
    "        train = pickle.load(f)\n",
    "    with open(traffic_testing_file, mode='rb') as f:\n",
    "        test = pickle.load(f)\n",
    "    return train['features'], train['labels'], test['features'], test['labels']\n",
    "\n",
    "\n",
    "# NOTE: it will take a while on first use since Keras will download the dataset\n",
    "def load_cifar10():\n",
    "    (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# Resizing all at once will take up too much data, so we resize it per batch\n",
    "# VGG, Inception, and ResNet expect a (224, 224, 3) input\n",
    "def gen_and_resize_data(data, labels, batch_size, size=(224, 224)):\n",
    "    def _f():\n",
    "        start = 0\n",
    "        end = start + batch_size\n",
    "        n = data.shape[0]\n",
    "        while True:\n",
    "            X_batch_old, y_batch = data[start:end], labels[start:end]\n",
    "            X_batch = []\n",
    "            for i in range(X_batch_old.shape[0]):\n",
    "                img = resize(X_batch_old[i, ...], size)\n",
    "                X_batch.append(img)\n",
    "\n",
    "            X_batch = np.array(X_batch)\n",
    "            start += batch_size\n",
    "            end += batch_size\n",
    "            if start >= n:\n",
    "                start = 0\n",
    "                end = batch_size\n",
    "\n",
    "            yield (X_batch, y_batch)\n",
    "    return _f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "\n",
    "Before you try feature extraction on pretrained models it's a good idea to take a moment and run the classifier you used in the Traffic Sign project on the Cifar10 dataset. Cifar10 images are also (32, 32, 3) so the only thing you'll need to change is the number of classes to 10 instead of 43.\n",
    "\n",
    "Cool, now you have something to compare the Cifar10 feature extraction results with!\n",
    "\n",
    "Keep in mind the following as you experiment:\n",
    "\n",
    "_Does feature extraction outperform the Traffic Signs classifier on the Cifar10 dataset? Why?_\n",
    "\n",
    "_Does feature extraction outperform the Traffic Signs classifier on the Traffic Signs dataset? Why?_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load and preprocess data\n",
    "X_train, y_train, X_test, y_test = load_cifar10()\n",
    "# X_train, y_train, X_test, y_test = load_traffic()\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# 0-255 -> 0-1\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# constants\n",
    "nb_epochs = 3\n",
    "batch_size = 32\n",
    "nb_classes = 10 # NOTE: change this to 43 if using traffic sign data\n",
    "\n",
    "# define model\n",
    "input_tensor = Input(shape=(224, 224, 3))\n",
    "\n",
    "# NOTE: It will take a while on the first use since Keras will download the weights for the model\n",
    "# pretrained_model = VGG16(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
    "pretrained_model = InceptionV3(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
    "# pretrained_model = ResNet50(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
    "\n",
    "# if vgg stop after second maxpool\n",
    "# x = pretrained_model.layers[6].output\n",
    "\n",
    "# if inception\n",
    "# x = pretrained_model.layers[60].output\n",
    "\n",
    "# if resnet, stop after the activation of first conv block\n",
    "# x = pretrained_model.layers[17].output\n",
    "\n",
    "\n",
    "# NOTE: feel free to change this\n",
    "x = pretrained_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(nb_classes, activation='softmax')(x)\n",
    "model = Model(pretrained_model.input, x)\n",
    "\n",
    "# freeze pretrained model layers\n",
    "for layer in pretrained_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train the model\n",
    "train_gen = gen_and_resize_data(X_train, y_train)\n",
    "test_gen = gen_and_resize_data(X_test, y_test)\n",
    "model.fit_generator(\n",
    "    train_gen(),\n",
    "    X_train.shape[0],\n",
    "    nb_epoch,\n",
    "    nb_val_samples=X_test.shape[0],\n",
    "    validation_data=test_gen())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <keras.engine.topology.InputLayer object at 0x1593dc908>\n",
      "1 <keras.layers.convolutional.Convolution2D object at 0x1593dc898>\n",
      "2 <keras.layers.normalization.BatchNormalization object at 0x1593dd978>\n",
      "3 <keras.layers.convolutional.Convolution2D object at 0x15e108c88>\n",
      "4 <keras.layers.normalization.BatchNormalization object at 0x15c2bbf60>\n",
      "5 <keras.layers.convolutional.Convolution2D object at 0x15e072c88>\n",
      "6 <keras.layers.normalization.BatchNormalization object at 0x15e9230b8>\n",
      "7 <keras.layers.pooling.MaxPooling2D object at 0x15ea97d30>\n",
      "8 <keras.layers.convolutional.Convolution2D object at 0x15eb01160>\n",
      "9 <keras.layers.normalization.BatchNormalization object at 0x15e2185c0>\n",
      "10 <keras.layers.convolutional.Convolution2D object at 0x15eb38f60>\n",
      "11 <keras.layers.normalization.BatchNormalization object at 0x15f5e8978>\n",
      "12 <keras.layers.pooling.MaxPooling2D object at 0x15e159c18>\n",
      "13 <keras.layers.convolutional.Convolution2D object at 0x15f834cf8>\n",
      "14 <keras.layers.normalization.BatchNormalization object at 0x15f80bf28>\n",
      "15 <keras.layers.convolutional.Convolution2D object at 0x15a89d6a0>\n",
      "16 <keras.layers.convolutional.Convolution2D object at 0x15fe23ba8>\n",
      "17 <keras.layers.normalization.BatchNormalization object at 0x15a8b7e10>\n",
      "18 <keras.layers.normalization.BatchNormalization object at 0x15faceef0>\n",
      "19 <keras.layers.pooling.AveragePooling2D object at 0x15fb9d6d8>\n",
      "20 <keras.layers.convolutional.Convolution2D object at 0x15e1a9e48>\n",
      "21 <keras.layers.convolutional.Convolution2D object at 0x15f87ae48>\n",
      "22 <keras.layers.convolutional.Convolution2D object at 0x15fa86fd0>\n",
      "23 <keras.layers.convolutional.Convolution2D object at 0x163099630>\n",
      "24 <keras.layers.normalization.BatchNormalization object at 0x15a70c9e8>\n",
      "25 <keras.layers.normalization.BatchNormalization object at 0x15ebcd630>\n",
      "26 <keras.layers.normalization.BatchNormalization object at 0x15fe9cda0>\n",
      "27 <keras.layers.normalization.BatchNormalization object at 0x162c03b38>\n",
      "28 <keras.engine.topology.Merge object at 0x162c56c88>\n",
      "29 <keras.layers.convolutional.Convolution2D object at 0x1633eee80>\n",
      "30 <keras.layers.normalization.BatchNormalization object at 0x163186e80>\n",
      "31 <keras.layers.convolutional.Convolution2D object at 0x162cb2e48>\n",
      "32 <keras.layers.convolutional.Convolution2D object at 0x163336d30>\n",
      "33 <keras.layers.normalization.BatchNormalization object at 0x163545588>\n",
      "34 <keras.layers.normalization.BatchNormalization object at 0x1631fe780>\n",
      "35 <keras.layers.pooling.AveragePooling2D object at 0x1638e2fd0>\n",
      "36 <keras.layers.convolutional.Convolution2D object at 0x16383fef0>\n",
      "37 <keras.layers.convolutional.Convolution2D object at 0x16387a7f0>\n",
      "38 <keras.layers.convolutional.Convolution2D object at 0x157e69908>\n",
      "39 <keras.layers.convolutional.Convolution2D object at 0x1638e2e48>\n",
      "40 <keras.layers.normalization.BatchNormalization object at 0x162c8cf28>\n",
      "41 <keras.layers.normalization.BatchNormalization object at 0x163871080>\n",
      "42 <keras.layers.normalization.BatchNormalization object at 0x163227f60>\n",
      "43 <keras.layers.normalization.BatchNormalization object at 0x1639627b8>\n",
      "44 <keras.engine.topology.Merge object at 0x163e3ae48>\n",
      "45 <keras.layers.convolutional.Convolution2D object at 0x163e92f98>\n",
      "46 <keras.layers.normalization.BatchNormalization object at 0x164069748>\n",
      "47 <keras.layers.convolutional.Convolution2D object at 0x16390ce10>\n",
      "48 <keras.layers.convolutional.Convolution2D object at 0x163c94cc0>\n",
      "49 <keras.layers.normalization.BatchNormalization object at 0x163921f98>\n",
      "50 <keras.layers.normalization.BatchNormalization object at 0x163cb35f8>\n",
      "51 <keras.layers.pooling.AveragePooling2D object at 0x1640d6c18>\n",
      "52 <keras.layers.convolutional.Convolution2D object at 0x1634f6c50>\n",
      "53 <keras.layers.convolutional.Convolution2D object at 0x162db9e10>\n",
      "54 <keras.layers.convolutional.Convolution2D object at 0x163ed2f98>\n",
      "55 <keras.layers.convolutional.Convolution2D object at 0x1641f6160>\n",
      "56 <keras.layers.normalization.BatchNormalization object at 0x16350cc88>\n",
      "57 <keras.layers.normalization.BatchNormalization object at 0x1639dae10>\n",
      "58 <keras.layers.normalization.BatchNormalization object at 0x163eeef98>\n",
      "59 <keras.layers.normalization.BatchNormalization object at 0x16442deb8>\n",
      "60 <keras.engine.topology.Merge object at 0x165333da0>\n",
      "61 <keras.layers.convolutional.Convolution2D object at 0x165178f60>\n",
      "62 <keras.layers.normalization.BatchNormalization object at 0x158223668>\n",
      "63 <keras.layers.convolutional.Convolution2D object at 0x1656f1e10>\n",
      "64 <keras.layers.normalization.BatchNormalization object at 0x1657dcf98>\n",
      "65 <keras.layers.convolutional.Convolution2D object at 0x1653ddac8>\n",
      "66 <keras.layers.convolutional.Convolution2D object at 0x16580ce10>\n",
      "67 <keras.layers.normalization.BatchNormalization object at 0x165464e48>\n",
      "68 <keras.layers.normalization.BatchNormalization object at 0x165973e10>\n",
      "69 <keras.layers.pooling.MaxPooling2D object at 0x16599af98>\n",
      "70 <keras.engine.topology.Merge object at 0x16597ea90>\n",
      "71 <keras.layers.convolutional.Convolution2D object at 0x16734b550>\n",
      "72 <keras.layers.normalization.BatchNormalization object at 0x16676b588>\n",
      "73 <keras.layers.convolutional.Convolution2D object at 0x16730ef28>\n",
      "74 <keras.layers.normalization.BatchNormalization object at 0x1674b9d30>\n",
      "75 <keras.layers.convolutional.Convolution2D object at 0x1655e5c18>\n",
      "76 <keras.layers.convolutional.Convolution2D object at 0x167690e48>\n",
      "77 <keras.layers.normalization.BatchNormalization object at 0x165cb2f28>\n",
      "78 <keras.layers.normalization.BatchNormalization object at 0x15f131160>\n",
      "79 <keras.layers.convolutional.Convolution2D object at 0x165cceeb8>\n",
      "80 <keras.layers.convolutional.Convolution2D object at 0x167acc438>\n",
      "81 <keras.layers.normalization.BatchNormalization object at 0x165d0ee10>\n",
      "82 <keras.layers.normalization.BatchNormalization object at 0x168292e48>\n",
      "83 <keras.layers.pooling.AveragePooling2D object at 0x1686a3438>\n",
      "84 <keras.layers.convolutional.Convolution2D object at 0x1651eecf8>\n",
      "85 <keras.layers.convolutional.Convolution2D object at 0x165dc8dd8>\n",
      "86 <keras.layers.convolutional.Convolution2D object at 0x16850b240>\n",
      "87 <keras.layers.convolutional.Convolution2D object at 0x1682449b0>\n",
      "88 <keras.layers.normalization.BatchNormalization object at 0x1651eee80>\n",
      "89 <keras.layers.normalization.BatchNormalization object at 0x1670b6eb8>\n",
      "90 <keras.layers.normalization.BatchNormalization object at 0x16867f710>\n",
      "91 <keras.layers.normalization.BatchNormalization object at 0x168225fd0>\n",
      "92 <keras.engine.topology.Merge object at 0x168619d68>\n",
      "93 <keras.layers.convolutional.Convolution2D object at 0x1691e0da0>\n",
      "94 <keras.layers.normalization.BatchNormalization object at 0x1687fbe10>\n",
      "95 <keras.layers.convolutional.Convolution2D object at 0x1692a2860>\n",
      "96 <keras.layers.normalization.BatchNormalization object at 0x1692455c0>\n",
      "97 <keras.layers.convolutional.Convolution2D object at 0x168038fd0>\n",
      "98 <keras.layers.convolutional.Convolution2D object at 0x1686f2da0>\n",
      "99 <keras.layers.normalization.BatchNormalization object at 0x1687bfa20>\n",
      "100 <keras.layers.normalization.BatchNormalization object at 0x168727e80>\n",
      "101 <keras.layers.convolutional.Convolution2D object at 0x1688a18d0>\n",
      "102 <keras.layers.convolutional.Convolution2D object at 0x1697d3e48>\n",
      "103 <keras.layers.normalization.BatchNormalization object at 0x16862ff98>\n",
      "104 <keras.layers.normalization.BatchNormalization object at 0x169acb588>\n",
      "105 <keras.layers.pooling.AveragePooling2D object at 0x169de6e80>\n",
      "106 <keras.layers.convolutional.Convolution2D object at 0x16823ec18>\n",
      "107 <keras.layers.convolutional.Convolution2D object at 0x168fabac8>\n",
      "108 <keras.layers.convolutional.Convolution2D object at 0x1697177f0>\n",
      "109 <keras.layers.convolutional.Convolution2D object at 0x169950f28>\n",
      "110 <keras.layers.normalization.BatchNormalization object at 0x168625f28>\n",
      "111 <keras.layers.normalization.BatchNormalization object at 0x168fe2390>\n",
      "112 <keras.layers.normalization.BatchNormalization object at 0x16970c080>\n",
      "113 <keras.layers.normalization.BatchNormalization object at 0x169c2ec50>\n",
      "114 <keras.engine.topology.Merge object at 0x169d33e48>\n",
      "115 <keras.layers.convolutional.Convolution2D object at 0x16a831da0>\n",
      "116 <keras.layers.normalization.BatchNormalization object at 0x16a867e80>\n",
      "117 <keras.layers.convolutional.Convolution2D object at 0x163e777f0>\n",
      "118 <keras.layers.normalization.BatchNormalization object at 0x16a9c4e48>\n",
      "119 <keras.layers.convolutional.Convolution2D object at 0x16a0d0ac8>\n",
      "120 <keras.layers.convolutional.Convolution2D object at 0x16b5c6c18>\n",
      "121 <keras.layers.normalization.BatchNormalization object at 0x169ef0390>\n",
      "122 <keras.layers.normalization.BatchNormalization object at 0x16b5c6780>\n",
      "123 <keras.layers.convolutional.Convolution2D object at 0x16a693da0>\n",
      "124 <keras.layers.convolutional.Convolution2D object at 0x16b009e10>\n",
      "125 <keras.layers.normalization.BatchNormalization object at 0x169f1ee10>\n",
      "126 <keras.layers.normalization.BatchNormalization object at 0x16b080550>\n",
      "127 <keras.layers.pooling.AveragePooling2D object at 0x16b35cdd8>\n",
      "128 <keras.layers.convolutional.Convolution2D object at 0x169d95d30>\n",
      "129 <keras.layers.convolutional.Convolution2D object at 0x16a066860>\n",
      "130 <keras.layers.convolutional.Convolution2D object at 0x16b0a5e48>\n",
      "131 <keras.layers.convolutional.Convolution2D object at 0x16b378f60>\n",
      "132 <keras.layers.normalization.BatchNormalization object at 0x169df6da0>\n",
      "133 <keras.layers.normalization.BatchNormalization object at 0x16a52d5c0>\n",
      "134 <keras.layers.normalization.BatchNormalization object at 0x16b49afd0>\n",
      "135 <keras.layers.normalization.BatchNormalization object at 0x16b298cc0>\n",
      "136 <keras.engine.topology.Merge object at 0x16b2d4dd8>\n",
      "137 <keras.layers.convolutional.Convolution2D object at 0x16bef9c18>\n",
      "138 <keras.layers.normalization.BatchNormalization object at 0x16bef9780>\n",
      "139 <keras.layers.convolutional.Convolution2D object at 0x16c520e10>\n",
      "140 <keras.layers.normalization.BatchNormalization object at 0x16c3af550>\n",
      "141 <keras.layers.convolutional.Convolution2D object at 0x16bb765f8>\n",
      "142 <keras.layers.convolutional.Convolution2D object at 0x16c3d5e48>\n",
      "143 <keras.layers.normalization.BatchNormalization object at 0x16b571be0>\n",
      "144 <keras.layers.normalization.BatchNormalization object at 0x16ca0ffd0>\n",
      "145 <keras.layers.convolutional.Convolution2D object at 0x16bbb04a8>\n",
      "146 <keras.layers.convolutional.Convolution2D object at 0x16ca36dd8>\n",
      "147 <keras.layers.normalization.BatchNormalization object at 0x16b4c56d8>\n",
      "148 <keras.layers.normalization.BatchNormalization object at 0x16ccf3cf8>\n",
      "149 <keras.layers.pooling.AveragePooling2D object at 0x16cacae10>\n",
      "150 <keras.layers.convolutional.Convolution2D object at 0x16b436748>\n",
      "151 <keras.layers.convolutional.Convolution2D object at 0x16b4f95f8>\n",
      "152 <keras.layers.convolutional.Convolution2D object at 0x16cc94668>\n",
      "153 <keras.layers.convolutional.Convolution2D object at 0x16cddd320>\n",
      "154 <keras.layers.normalization.BatchNormalization object at 0x16b38be80>\n",
      "155 <keras.layers.normalization.BatchNormalization object at 0x16b6c2e48>\n",
      "156 <keras.layers.normalization.BatchNormalization object at 0x16c0809b0>\n",
      "157 <keras.layers.normalization.BatchNormalization object at 0x16caffe48>\n",
      "158 <keras.engine.topology.Merge object at 0x16d1a9cc0>\n",
      "159 <keras.layers.convolutional.Convolution2D object at 0x16d512e10>\n",
      "160 <keras.layers.normalization.BatchNormalization object at 0x16d937eb8>\n",
      "161 <keras.layers.convolutional.Convolution2D object at 0x16d0a1dd8>\n",
      "162 <keras.layers.normalization.BatchNormalization object at 0x16d057518>\n",
      "163 <keras.layers.convolutional.Convolution2D object at 0x16caa1470>\n",
      "164 <keras.layers.convolutional.Convolution2D object at 0x16cffdeb8>\n",
      "165 <keras.layers.normalization.BatchNormalization object at 0x16d1c9f98>\n",
      "166 <keras.layers.normalization.BatchNormalization object at 0x16cf76630>\n",
      "167 <keras.layers.convolutional.Convolution2D object at 0x16d634e10>\n",
      "168 <keras.layers.convolutional.Convolution2D object at 0x16cf94da0>\n",
      "169 <keras.layers.normalization.BatchNormalization object at 0x16d65ee48>\n",
      "170 <keras.layers.normalization.BatchNormalization object at 0x16d9a7c18>\n",
      "171 <keras.layers.pooling.AveragePooling2D object at 0x16e282f28>\n",
      "172 <keras.engine.topology.Merge object at 0x16d9da198>\n",
      "173 <keras.layers.convolutional.Convolution2D object at 0x16e929f60>\n",
      "174 <keras.layers.normalization.BatchNormalization object at 0x16ec04fd0>\n",
      "175 <keras.layers.convolutional.Convolution2D object at 0x16e23d588>\n",
      "176 <keras.layers.convolutional.Convolution2D object at 0x16ece95c0>\n",
      "177 <keras.layers.normalization.BatchNormalization object at 0x16ddcfb70>\n",
      "178 <keras.layers.normalization.BatchNormalization object at 0x16e9b3940>\n",
      "179 <keras.layers.convolutional.Convolution2D object at 0x16ea75f60>\n",
      "180 <keras.layers.convolutional.Convolution2D object at 0x16ec7de10>\n",
      "181 <keras.layers.convolutional.Convolution2D object at 0x16ecaff98>\n",
      "182 <keras.layers.convolutional.Convolution2D object at 0x16f298e10>\n",
      "183 <keras.layers.pooling.AveragePooling2D object at 0x16f228400>\n",
      "184 <keras.layers.convolutional.Convolution2D object at 0x16e298c18>\n",
      "185 <keras.layers.normalization.BatchNormalization object at 0x16e9e2668>\n",
      "186 <keras.layers.normalization.BatchNormalization object at 0x16ec93f98>\n",
      "187 <keras.layers.normalization.BatchNormalization object at 0x16f2526a0>\n",
      "188 <keras.layers.normalization.BatchNormalization object at 0x16f2c2e48>\n",
      "189 <keras.layers.convolutional.Convolution2D object at 0x16fe15e80>\n",
      "190 <keras.layers.normalization.BatchNormalization object at 0x16de13630>\n",
      "191 <keras.engine.topology.Merge object at 0x16e929e10>\n",
      "192 <keras.engine.topology.Merge object at 0x16f228e10>\n",
      "193 <keras.layers.normalization.BatchNormalization object at 0x16fe35128>\n",
      "194 <keras.engine.topology.Merge object at 0x16fba7fd0>\n",
      "195 <keras.layers.convolutional.Convolution2D object at 0x16f5a1f98>\n",
      "196 <keras.layers.normalization.BatchNormalization object at 0x156327fd0>\n",
      "197 <keras.layers.convolutional.Convolution2D object at 0x16dd21e48>\n",
      "198 <keras.layers.convolutional.Convolution2D object at 0x1563ba940>\n",
      "199 <keras.layers.normalization.BatchNormalization object at 0x16f67afd0>\n",
      "200 <keras.layers.normalization.BatchNormalization object at 0x156402dd8>\n",
      "201 <keras.layers.convolutional.Convolution2D object at 0x16dd9bd30>\n",
      "202 <keras.layers.convolutional.Convolution2D object at 0x16c558668>\n",
      "203 <keras.layers.convolutional.Convolution2D object at 0x156346f98>\n",
      "204 <keras.layers.convolutional.Convolution2D object at 0x16db076a0>\n",
      "205 <keras.layers.pooling.AveragePooling2D object at 0x16f7a8ef0>\n",
      "206 <keras.layers.convolutional.Convolution2D object at 0x16fba7e48>\n",
      "207 <keras.layers.normalization.BatchNormalization object at 0x16ddb8cf8>\n",
      "208 <keras.layers.normalization.BatchNormalization object at 0x16f5e59b0>\n",
      "209 <keras.layers.normalization.BatchNormalization object at 0x16db53c88>\n",
      "210 <keras.layers.normalization.BatchNormalization object at 0x16db22e10>\n",
      "211 <keras.layers.convolutional.Convolution2D object at 0x16fb77860>\n",
      "212 <keras.layers.normalization.BatchNormalization object at 0x16dd7bc50>\n",
      "213 <keras.engine.topology.Merge object at 0x15645fe10>\n",
      "214 <keras.engine.topology.Merge object at 0x16fb62e48>\n",
      "215 <keras.layers.normalization.BatchNormalization object at 0x16f966da0>\n",
      "216 <keras.engine.topology.Merge object at 0x170f0c4a8>\n"
     ]
    }
   ],
   "source": [
    "for i, l in enumerate(pretrained_model.layers): # 0-5 is input, 17 is the first activation after merge\n",
    "    print(i, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MaxPool_5:0' shape=(?, 56, 56, 128) dtype=float32>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model.layers[6].output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "By now you should have a good feel for feature extraction and when it might be a good choice. To end this lab, let's summarize when we should consider:\n",
    "\n",
    "1. Feature extraction (train only the top-level of the network, the rest of the network remains fixed)\n",
    "2. Finetuning (train the entire network end-to-end, start with pretrained weights)\n",
    "3. Training from scratch (train the entire network end-to-end, start from random weights)\n",
    "\n",
    "**Consider feature extraction when ...**\n",
    "\n",
    "If dataset is small and similar to the original dataset. The higher-level features learned from the original dataset should be relevant to the new dataset.\n",
    "\n",
    "**Consider finetuning when ...** \n",
    "\n",
    "If the dataset is large and similar to the original dataset. In this case we should be much more confident we won't overfit so it should be safe to alter the original weights.\n",
    "\n",
    "If the dataset is small and very different from the original dataset. You could also make the case for training from scratch. If we choose to finetune it might be a good idea to only use features found earlier on in the network, features found later might be too dataset specific.\n",
    "\n",
    "**Consider training from scratch when ...**\n",
    "\n",
    "If the dataset is large and very different from the original dataset. In this case we have enough data to confidently train from scratch. However, even in this case it might be more beneficial to finetune and the entire network from pretrained weights.\n",
    "\n",
    "---\n",
    "\n",
    "Most importantly, keep in mind for a lot of problems you won't need an architecture as complicated and powerful as VGG, Inception, or ResNet. These architectures were made for the task of classifying thousands of complex classes. A much smaller network might be a much better fit for your problem, especially if you can comfortably train it on moderate hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
