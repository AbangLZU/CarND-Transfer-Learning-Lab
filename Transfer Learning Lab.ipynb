{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning with VGG, Inception and ResNet\n",
    "\n",
    "In this lab, you will continue exploring transfer learning. You've already explored feature extraction with Alexnet and TensorFlow. Next, you will use Keras to explore feature extraction with the VGG, Inception and ResNet architectures. The models you will use were trained for days or weeks on the [ImageNet dataset](http://www.image-net.org/). Thus, the weights escapsulate higher-level features learned from thousands of classes.\n",
    "\n",
    "We'll use two datasets in this lab:\n",
    "\n",
    "1. [German Traffic Sign Dataset](http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset)\n",
    "2. [Cifar10](https://www.cs.toronto.edu/~kriz/cifar.html)\n",
    "\n",
    "How will the pretrained model perform on the new datasets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense, Flatten, Input\n",
    "from keras.models import Model\n",
    "from keras.datasets import cifar10\n",
    "from skimage.transform import resize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data functions\n",
    "traffic_training_file = ''\n",
    "traffic_testing_file = ''\n",
    "\n",
    "def load_traffic():\n",
    "    with open(traffic_training_file, mode='rb') as f:\n",
    "        train = pickle.load(f)\n",
    "    with open(traffic_testing_file, mode='rb') as f:\n",
    "        test = pickle.load(f)\n",
    "    return train['features'], train['labels'], test['features'], test['labels']\n",
    "\n",
    "\n",
    "# NOTE: it will take a while on first use since Keras will download the dataset\n",
    "def load_cifar10():\n",
    "    (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# Resizing all at once will take up too much data, so we resize it per batch\n",
    "# VGG, Inception, and ResNet expect a (224, 224, 3) input\n",
    "def gen_and_resize_data(data, labels, batch_size, size=(224, 224)):\n",
    "    def _f():\n",
    "        start = 0\n",
    "        end = start + batch_size\n",
    "        n = data.shape[0]\n",
    "        while True:\n",
    "            X_batch_old, y_batch = data[start:end], labels[start:end]\n",
    "            X_batch = []\n",
    "            for i in range(X_batch_old.shape[0]):\n",
    "                img = resize(X_batch_old[i, ...], size)\n",
    "                X_batch.append(img)\n",
    "\n",
    "            X_batch = np.array(X_batch)\n",
    "            start += batch_size\n",
    "            end += batch_size\n",
    "            if start >= n:\n",
    "                start = 0\n",
    "                end = batch_size\n",
    "\n",
    "            yield (X_batch, y_batch)\n",
    "    return _f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "\n",
    "Before you try feature extraction on pretrained models it's a good idea to take a moment and run the classifier you used in the Traffic Sign project on the Cifar10 dataset. Cifar10 images are also (32, 32, 3) so the only thing you'll need to change is the number of classes to 10 instead of 43.\n",
    "\n",
    "Cool, now you have something to compare the Cifar10 feature extraction results with!\n",
    "\n",
    "Keep in mind the following as you experiment:\n",
    "\n",
    "_Does feature extraction outperform the Traffic Signs classifier on the Cifar10 dataset? Why?_\n",
    "\n",
    "_Does feature extraction outperform the Traffic Signs classifier on the Traffic Signs dataset? Why?_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load and preprocess data\n",
    "X_train, y_train, X_test, y_test = load_cifar10()\n",
    "# X_train, y_train, X_test, y_test = load_traffic()\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# 0-255 -> 0-1\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# constants\n",
    "nb_epochs = 3\n",
    "batch_size = 32\n",
    "nb_classes = 10 # NOTE: change this to 43 if using traffic sign data\n",
    "\n",
    "# define model\n",
    "input_tensor = Input(shape=(224, 224, 3))\n",
    "\n",
    "# NOTE: It will take a while on the first use since Keras will download the weights for the model\n",
    "\n",
    "pretrained_model = VGG16(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
    "x = pretrained_model.layers[6].output # after second maxpool\n",
    "\n",
    "# pretrained_model = InceptionV3(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
    "# x = pretrained_model.layers[28].output # after first inception block merge\n",
    "\n",
    "# pretrained_model = ResNet50(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
    "# x = pretrained_model.layers[17].output # after first conv block merge\n",
    "\n",
    "# NOTE: feel free to change this\n",
    "x = Flatten()(x)\n",
    "x = Dense(nb_classes, activation='softmax')(x)\n",
    "model = Model(pretrained_model.input, x)\n",
    "\n",
    "# freeze pretrained model layers\n",
    "for layer in pretrained_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <keras.engine.topology.InputLayer object at 0x170ec49b0>\n",
      "1 <keras.layers.convolutional.Convolution2D object at 0x170eb8e80>\n",
      "2 <keras.layers.normalization.BatchNormalization object at 0x167925a20>\n",
      "3 <keras.layers.convolutional.Convolution2D object at 0x172a7ce80>\n",
      "4 <keras.layers.normalization.BatchNormalization object at 0x1679e0e80>\n",
      "5 <keras.layers.convolutional.Convolution2D object at 0x174778d30>\n",
      "6 <keras.layers.normalization.BatchNormalization object at 0x16cd6e940>\n",
      "7 <keras.layers.pooling.MaxPooling2D object at 0x172632be0>\n",
      "8 <keras.layers.convolutional.Convolution2D object at 0x173c18e10>\n",
      "9 <keras.layers.normalization.BatchNormalization object at 0x173fb0908>\n",
      "10 <keras.layers.convolutional.Convolution2D object at 0x173f17668>\n",
      "11 <keras.layers.normalization.BatchNormalization object at 0x1720af9b0>\n",
      "12 <keras.layers.pooling.MaxPooling2D object at 0x172094e10>\n",
      "13 <keras.layers.convolutional.Convolution2D object at 0x1747d9c50>\n",
      "14 <keras.layers.normalization.BatchNormalization object at 0x17554f2e8>\n",
      "15 <keras.layers.convolutional.Convolution2D object at 0x173e1ddd8>\n",
      "16 <keras.layers.convolutional.Convolution2D object at 0x17556cc50>\n",
      "17 <keras.layers.normalization.BatchNormalization object at 0x173e38cf8>\n",
      "18 <keras.layers.normalization.BatchNormalization object at 0x1747bf358>\n",
      "19 <keras.layers.pooling.AveragePooling2D object at 0x1758cbe10>\n",
      "20 <keras.layers.convolutional.Convolution2D object at 0x1720ea5f8>\n",
      "21 <keras.layers.convolutional.Convolution2D object at 0x17026de80>\n",
      "22 <keras.layers.convolutional.Convolution2D object at 0x17507d8d0>\n",
      "23 <keras.layers.convolutional.Convolution2D object at 0x1755e28d0>\n",
      "24 <keras.layers.normalization.BatchNormalization object at 0x1720ac828>\n",
      "25 <keras.layers.normalization.BatchNormalization object at 0x170282a20>\n",
      "26 <keras.layers.normalization.BatchNormalization object at 0x1750aacf8>\n",
      "27 <keras.layers.normalization.BatchNormalization object at 0x1758e2048>\n",
      "28 <keras.engine.topology.Merge object at 0x17587b588>\n",
      "29 <keras.layers.convolutional.Convolution2D object at 0x1781474a8>\n",
      "30 <keras.layers.normalization.BatchNormalization object at 0x1741dcd30>\n",
      "31 <keras.layers.convolutional.Convolution2D object at 0x175a81be0>\n",
      "32 <keras.layers.convolutional.Convolution2D object at 0x177b32da0>\n",
      "33 <keras.layers.normalization.BatchNormalization object at 0x175b05da0>\n",
      "34 <keras.layers.normalization.BatchNormalization object at 0x176124e80>\n",
      "35 <keras.layers.pooling.AveragePooling2D object at 0x176062dd8>\n",
      "36 <keras.layers.convolutional.Convolution2D object at 0x17589dda0>\n",
      "37 <keras.layers.convolutional.Convolution2D object at 0x175a13e10>\n",
      "38 <keras.layers.convolutional.Convolution2D object at 0x176140c18>\n",
      "39 <keras.layers.convolutional.Convolution2D object at 0x17607cf60>\n",
      "40 <keras.layers.normalization.BatchNormalization object at 0x175b63f98>\n",
      "41 <keras.layers.normalization.BatchNormalization object at 0x175a7cef0>\n",
      "42 <keras.layers.normalization.BatchNormalization object at 0x177b58da0>\n",
      "43 <keras.layers.normalization.BatchNormalization object at 0x17627ed68>\n",
      "44 <keras.engine.topology.Merge object at 0x177b99e10>\n",
      "45 <keras.layers.convolutional.Convolution2D object at 0x1779f0da0>\n",
      "46 <keras.layers.normalization.BatchNormalization object at 0x176f12d30>\n",
      "47 <keras.layers.convolutional.Convolution2D object at 0x176e9ff60>\n",
      "48 <keras.layers.convolutional.Convolution2D object at 0x176f38f98>\n",
      "49 <keras.layers.normalization.BatchNormalization object at 0x177a50cc0>\n",
      "50 <keras.layers.normalization.BatchNormalization object at 0x176f7bd30>\n",
      "51 <keras.layers.pooling.AveragePooling2D object at 0x177d32be0>\n",
      "52 <keras.layers.convolutional.Convolution2D object at 0x1762a5da0>\n",
      "53 <keras.layers.convolutional.Convolution2D object at 0x177a9fc18>\n",
      "54 <keras.layers.convolutional.Convolution2D object at 0x177fbde10>\n",
      "55 <keras.layers.convolutional.Convolution2D object at 0x177c5ee10>\n",
      "56 <keras.layers.normalization.BatchNormalization object at 0x177baeef0>\n",
      "57 <keras.layers.normalization.BatchNormalization object at 0x17796ed30>\n",
      "58 <keras.layers.normalization.BatchNormalization object at 0x17791da20>\n",
      "59 <keras.layers.normalization.BatchNormalization object at 0x177d66940>\n",
      "60 <keras.engine.topology.Merge object at 0x177dc7e80>\n",
      "61 <keras.layers.convolutional.Convolution2D object at 0x17800de48>\n",
      "62 <keras.layers.normalization.BatchNormalization object at 0x177f0ce10>\n",
      "63 <keras.layers.convolutional.Convolution2D object at 0x177e897f0>\n",
      "64 <keras.layers.normalization.BatchNormalization object at 0x177f3c080>\n",
      "65 <keras.layers.convolutional.Convolution2D object at 0x176ecff28>\n",
      "66 <keras.layers.convolutional.Convolution2D object at 0x177f41fd0>\n",
      "67 <keras.layers.normalization.BatchNormalization object at 0x17818af60>\n",
      "68 <keras.layers.normalization.BatchNormalization object at 0x177f41588>\n",
      "69 <keras.layers.pooling.MaxPooling2D object at 0x178106cc0>\n",
      "70 <keras.engine.topology.Merge object at 0x1780b0438>\n",
      "71 <keras.layers.convolutional.Convolution2D object at 0x179843cf8>\n",
      "72 <keras.layers.normalization.BatchNormalization object at 0x1797b44e0>\n",
      "73 <keras.layers.convolutional.Convolution2D object at 0x1798d8eb8>\n",
      "74 <keras.layers.normalization.BatchNormalization object at 0x179e9fe10>\n",
      "75 <keras.layers.convolutional.Convolution2D object at 0x178b7abe0>\n",
      "76 <keras.layers.convolutional.Convolution2D object at 0x179fb45c0>\n",
      "77 <keras.layers.normalization.BatchNormalization object at 0x1792d5e80>\n",
      "78 <keras.layers.normalization.BatchNormalization object at 0x179f55ba8>\n",
      "79 <keras.layers.convolutional.Convolution2D object at 0x1792f1438>\n",
      "80 <keras.layers.convolutional.Convolution2D object at 0x17aa43eb8>\n",
      "81 <keras.layers.normalization.BatchNormalization object at 0x1793d96a0>\n",
      "82 <keras.layers.normalization.BatchNormalization object at 0x17aa63898>\n",
      "83 <keras.layers.pooling.AveragePooling2D object at 0x17a2f9eb8>\n",
      "84 <keras.layers.convolutional.Convolution2D object at 0x1780c5860>\n",
      "85 <keras.layers.convolutional.Convolution2D object at 0x179422f28>\n",
      "86 <keras.layers.convolutional.Convolution2D object at 0x177cdb438>\n",
      "87 <keras.layers.convolutional.Convolution2D object at 0x17aec2cf8>\n",
      "88 <keras.layers.normalization.BatchNormalization object at 0x1780c56d8>\n",
      "89 <keras.layers.normalization.BatchNormalization object at 0x1793ece80>\n",
      "90 <keras.layers.normalization.BatchNormalization object at 0x17aaddf98>\n",
      "91 <keras.layers.normalization.BatchNormalization object at 0x17acdcfd0>\n",
      "92 <keras.engine.topology.Merge object at 0x17a776e10>\n",
      "93 <keras.layers.convolutional.Convolution2D object at 0x17c4d5f98>\n",
      "94 <keras.layers.normalization.BatchNormalization object at 0x17c6f7550>\n",
      "95 <keras.layers.convolutional.Convolution2D object at 0x17d2d9eb8>\n",
      "96 <keras.layers.normalization.BatchNormalization object at 0x179470a90>\n",
      "97 <keras.layers.convolutional.Convolution2D object at 0x17af0b470>\n",
      "98 <keras.layers.convolutional.Convolution2D object at 0x175546588>\n",
      "99 <keras.layers.normalization.BatchNormalization object at 0x17b1bed68>\n",
      "100 <keras.layers.normalization.BatchNormalization object at 0x17df9fe10>\n",
      "101 <keras.layers.convolutional.Convolution2D object at 0x17b1d82e8>\n",
      "102 <keras.layers.convolutional.Convolution2D object at 0x17d6127f0>\n",
      "103 <keras.layers.normalization.BatchNormalization object at 0x17c0d0eb8>\n",
      "104 <keras.layers.normalization.BatchNormalization object at 0x17d607080>\n",
      "105 <keras.layers.pooling.AveragePooling2D object at 0x17fd29cc0>\n",
      "106 <keras.layers.convolutional.Convolution2D object at 0x17a776ef0>\n",
      "107 <keras.layers.convolutional.Convolution2D object at 0x17c559dd8>\n",
      "108 <keras.layers.convolutional.Convolution2D object at 0x17e3d0fd0>\n",
      "109 <keras.layers.convolutional.Convolution2D object at 0x17f915438>\n",
      "110 <keras.layers.normalization.BatchNormalization object at 0x17aed2eb8>\n",
      "111 <keras.layers.normalization.BatchNormalization object at 0x17c4b06d8>\n",
      "112 <keras.layers.normalization.BatchNormalization object at 0x17e3d0588>\n",
      "113 <keras.layers.normalization.BatchNormalization object at 0x17f93dc88>\n",
      "114 <keras.engine.topology.Merge object at 0x17e5c4e10>\n",
      "115 <keras.layers.convolutional.Convolution2D object at 0x17f784f60>\n",
      "116 <keras.layers.normalization.BatchNormalization object at 0x1808b8fd0>\n",
      "117 <keras.layers.convolutional.Convolution2D object at 0x1811b55f8>\n",
      "118 <keras.layers.normalization.BatchNormalization object at 0x18030abe0>\n",
      "119 <keras.layers.convolutional.Convolution2D object at 0x17f7bbcc0>\n",
      "120 <keras.layers.convolutional.Convolution2D object at 0x1815c6ac8>\n",
      "121 <keras.layers.normalization.BatchNormalization object at 0x17f7db5f8>\n",
      "122 <keras.layers.normalization.BatchNormalization object at 0x181587f60>\n",
      "123 <keras.layers.convolutional.Convolution2D object at 0x17e00c668>\n",
      "124 <keras.layers.convolutional.Convolution2D object at 0x1815addd8>\n",
      "125 <keras.layers.normalization.BatchNormalization object at 0x17fecca58>\n",
      "126 <keras.layers.normalization.BatchNormalization object at 0x180ab5d68>\n",
      "127 <keras.layers.pooling.AveragePooling2D object at 0x1814b9860>\n",
      "128 <keras.layers.convolutional.Convolution2D object at 0x17c0705f8>\n",
      "129 <keras.layers.convolutional.Convolution2D object at 0x180961d30>\n",
      "130 <keras.layers.convolutional.Convolution2D object at 0x180ae7e48>\n",
      "131 <keras.layers.convolutional.Convolution2D object at 0x1814af668>\n",
      "132 <keras.layers.normalization.BatchNormalization object at 0x17e5f2f98>\n",
      "133 <keras.layers.normalization.BatchNormalization object at 0x17f712940>\n",
      "134 <keras.layers.normalization.BatchNormalization object at 0x181549e10>\n",
      "135 <keras.layers.normalization.BatchNormalization object at 0x1814559e8>\n",
      "136 <keras.engine.topology.Merge object at 0x181310da0>\n",
      "137 <keras.layers.convolutional.Convolution2D object at 0x180f21668>\n",
      "138 <keras.layers.normalization.BatchNormalization object at 0x182ce6a58>\n",
      "139 <keras.layers.convolutional.Convolution2D object at 0x182ebcd30>\n",
      "140 <keras.layers.normalization.BatchNormalization object at 0x182d4b940>\n",
      "141 <keras.layers.convolutional.Convolution2D object at 0x1813bb5f8>\n",
      "142 <keras.layers.convolutional.Convolution2D object at 0x180f84f60>\n",
      "143 <keras.layers.normalization.BatchNormalization object at 0x1813f8860>\n",
      "144 <keras.layers.normalization.BatchNormalization object at 0x1832a2fd0>\n",
      "145 <keras.layers.convolutional.Convolution2D object at 0x182ab8860>\n",
      "146 <keras.layers.convolutional.Convolution2D object at 0x1841285f8>\n",
      "147 <keras.layers.normalization.BatchNormalization object at 0x182b14630>\n",
      "148 <keras.layers.normalization.BatchNormalization object at 0x182d94be0>\n",
      "149 <keras.layers.pooling.AveragePooling2D object at 0x18385fdd8>\n",
      "150 <keras.layers.convolutional.Convolution2D object at 0x180fdeac8>\n",
      "151 <keras.layers.convolutional.Convolution2D object at 0x182b6acc0>\n",
      "152 <keras.layers.convolutional.Convolution2D object at 0x1841b1ac8>\n",
      "153 <keras.layers.convolutional.Convolution2D object at 0x184590748>\n",
      "154 <keras.layers.normalization.BatchNormalization object at 0x181325e10>\n",
      "155 <keras.layers.normalization.BatchNormalization object at 0x182b895f8>\n",
      "156 <keras.layers.normalization.BatchNormalization object at 0x183837f60>\n",
      "157 <keras.layers.normalization.BatchNormalization object at 0x183f3ab70>\n",
      "158 <keras.engine.topology.Merge object at 0x184556f60>\n",
      "159 <keras.layers.convolutional.Convolution2D object at 0x183e60550>\n",
      "160 <keras.layers.normalization.BatchNormalization object at 0x183eda588>\n",
      "161 <keras.layers.convolutional.Convolution2D object at 0x184c5de10>\n",
      "162 <keras.layers.normalization.BatchNormalization object at 0x184c86828>\n",
      "163 <keras.layers.convolutional.Convolution2D object at 0x183f61eb8>\n",
      "164 <keras.layers.convolutional.Convolution2D object at 0x183e1bbe0>\n",
      "165 <keras.layers.normalization.BatchNormalization object at 0x1838cb780>\n",
      "166 <keras.layers.normalization.BatchNormalization object at 0x18485ae80>\n",
      "167 <keras.layers.convolutional.Convolution2D object at 0x182df8fd0>\n",
      "168 <keras.layers.convolutional.Convolution2D object at 0x183879438>\n",
      "169 <keras.layers.normalization.BatchNormalization object at 0x183fa7da0>\n",
      "170 <keras.layers.normalization.BatchNormalization object at 0x184a756a0>\n",
      "171 <keras.layers.pooling.AveragePooling2D object at 0x1851bff28>\n",
      "172 <keras.engine.topology.Merge object at 0x1847b1198>\n",
      "173 <keras.layers.convolutional.Convolution2D object at 0x18505ad30>\n",
      "174 <keras.layers.normalization.BatchNormalization object at 0x1850efcc0>\n",
      "175 <keras.layers.convolutional.Convolution2D object at 0x186b914a8>\n",
      "176 <keras.layers.convolutional.Convolution2D object at 0x18512c390>\n",
      "177 <keras.layers.normalization.BatchNormalization object at 0x184ec9d30>\n",
      "178 <keras.layers.normalization.BatchNormalization object at 0x17e37af98>\n",
      "179 <keras.layers.convolutional.Convolution2D object at 0x1858f7da0>\n",
      "180 <keras.layers.convolutional.Convolution2D object at 0x184e21c18>\n",
      "181 <keras.layers.convolutional.Convolution2D object at 0x171533eb8>\n",
      "182 <keras.layers.convolutional.Convolution2D object at 0x17e3296a0>\n",
      "183 <keras.layers.pooling.AveragePooling2D object at 0x178d71588>\n",
      "184 <keras.layers.convolutional.Convolution2D object at 0x184a94c18>\n",
      "185 <keras.layers.normalization.BatchNormalization object at 0x184f06e80>\n",
      "186 <keras.layers.normalization.BatchNormalization object at 0x1858a1da0>\n",
      "187 <keras.layers.normalization.BatchNormalization object at 0x185d90e80>\n",
      "188 <keras.layers.normalization.BatchNormalization object at 0x17e344f28>\n",
      "189 <keras.layers.convolutional.Convolution2D object at 0x178e35780>\n",
      "190 <keras.layers.normalization.BatchNormalization object at 0x184ab22e8>\n",
      "191 <keras.engine.topology.Merge object at 0x18505add8>\n",
      "192 <keras.engine.topology.Merge object at 0x178d71f60>\n",
      "193 <keras.layers.normalization.BatchNormalization object at 0x178e3fba8>\n",
      "194 <keras.engine.topology.Merge object at 0x178fcde10>\n",
      "195 <keras.layers.convolutional.Convolution2D object at 0x18671eba8>\n",
      "196 <keras.layers.normalization.BatchNormalization object at 0x184784be0>\n",
      "197 <keras.layers.convolutional.Convolution2D object at 0x178f92fd0>\n",
      "198 <keras.layers.convolutional.Convolution2D object at 0x186b9ee10>\n",
      "199 <keras.layers.normalization.BatchNormalization object at 0x179047a20>\n",
      "200 <keras.layers.normalization.BatchNormalization object at 0x186bc7828>\n",
      "201 <keras.layers.convolutional.Convolution2D object at 0x1860eaf60>\n",
      "202 <keras.layers.convolutional.Convolution2D object at 0x184fefc18>\n",
      "203 <keras.layers.convolutional.Convolution2D object at 0x186207be0>\n",
      "204 <keras.layers.convolutional.Convolution2D object at 0x187640438>\n",
      "205 <keras.layers.pooling.AveragePooling2D object at 0x17622eda0>\n",
      "206 <keras.layers.convolutional.Convolution2D object at 0x178dfc8d0>\n",
      "207 <keras.layers.normalization.BatchNormalization object at 0x184f20cc0>\n",
      "208 <keras.layers.normalization.BatchNormalization object at 0x184fafd30>\n",
      "209 <keras.layers.normalization.BatchNormalization object at 0x1880b3e80>\n",
      "210 <keras.layers.normalization.BatchNormalization object at 0x18776c6a0>\n",
      "211 <keras.layers.convolutional.Convolution2D object at 0x18619b940>\n",
      "212 <keras.layers.normalization.BatchNormalization object at 0x178fe21d0>\n",
      "213 <keras.engine.topology.Merge object at 0x184761da0>\n",
      "214 <keras.engine.topology.Merge object at 0x186188f28>\n",
      "215 <keras.layers.normalization.BatchNormalization object at 0x1861bca58>\n",
      "216 <keras.engine.topology.Merge object at 0x1876ad4a8>\n"
     ]
    }
   ],
   "source": [
    "# we can use this to see where to change the output of the pretrained model\n",
    "for i, l in enumerate(pretrained_model.layers):\n",
    "    print(i, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train the model\n",
    "train_gen = gen_and_resize_data(X_train, y_train)\n",
    "test_gen = gen_and_resize_data(X_test, y_test)\n",
    "model.fit_generator(\n",
    "    train_gen(),\n",
    "    X_train.shape[0],\n",
    "    nb_epoch,\n",
    "    nb_val_samples=X_test.shape[0],\n",
    "    validation_data=test_gen())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MaxPool_5:0' shape=(?, 56, 56, 128) dtype=float32>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model.layers[6].output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "By now you should have a good feel for feature extraction and when it might be a good choice. To end this lab, let's summarize when we should consider:\n",
    "\n",
    "1. Feature extraction (train only the top-level of the network, the rest of the network remains fixed)\n",
    "2. Finetuning (train the entire network end-to-end, start with pretrained weights)\n",
    "3. Training from scratch (train the entire network end-to-end, start from random weights)\n",
    "\n",
    "**Consider feature extraction when ...**\n",
    "\n",
    "If dataset is small and similar to the original dataset. The higher-level features learned from the original dataset should be relevant to the new dataset.\n",
    "\n",
    "**Consider finetuning when ...** \n",
    "\n",
    "If the dataset is large and similar to the original dataset. In this case we should be much more confident we won't overfit so it should be safe to alter the original weights.\n",
    "\n",
    "If the dataset is small and very different from the original dataset. You could also make the case for training from scratch. If we choose to finetune it might be a good idea to only use features found earlier on in the network, features found later might be too dataset specific.\n",
    "\n",
    "**Consider training from scratch when ...**\n",
    "\n",
    "If the dataset is large and very different from the original dataset. In this case we have enough data to confidently train from scratch. However, even in this case it might be more beneficial to finetune and the entire network from pretrained weights.\n",
    "\n",
    "---\n",
    "\n",
    "Most importantly, keep in mind for a lot of problems you won't need an architecture as complicated and powerful as VGG, Inception, or ResNet. These architectures were made for the task of classifying thousands of complex classes. A much smaller network might be a much better fit for your problem, especially if you can comfortably train it on moderate hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
