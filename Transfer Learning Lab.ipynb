{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning with VGG, Inception and ResNet\n",
    "\n",
    "In this lab, you will continue exploring transfer learning. You've already explored feature extraction with Alexnet and TensorFlow. Next, you will use Keras to explore feature extraction with the VGG, Inception and ResNet architectures. The models you will use were trained for days or weeks on the [ImageNet dataset](http://www.image-net.org/). Thus, the weights escapsulate higher-level features learned from thousands of classes.\n",
    "\n",
    "We'll use two datasets in this lab:\n",
    "\n",
    "1. [German Traffic Sign Dataset](http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset)\n",
    "2. [Cifar10](https://www.cs.toronto.edu/~kriz/cifar.html)\n",
    "\n",
    "How will the pretrained model perform on the new datasets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense, Flatten, Input\n",
    "from keras.models import Model\n",
    "from keras.datasets import cifar10\n",
    "from skimage.transform import resize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data functions\n",
    "traffic_training_file = ''\n",
    "traffic_testing_file = ''\n",
    "\n",
    "def load_traffic():\n",
    "    with open(traffic_training_file, mode='rb') as f:\n",
    "        train = pickle.load(f)\n",
    "    with open(traffic_testing_file, mode='rb') as f:\n",
    "        test = pickle.load(f)\n",
    "    return train['features'], train['labels'], test['features'], test['labels']\n",
    "\n",
    "\n",
    "# NOTE: it will take a while on first use since Keras will download the dataset\n",
    "def load_cifar10():\n",
    "    (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# Resizing all at once will take up too much data, so we resize it per batch\n",
    "# VGG, Inception, and ResNet expect a (224, 224, 3) input\n",
    "def gen_and_resize_data(data, labels, batch_size, size=(224, 224)):\n",
    "    def _f():\n",
    "        start = 0\n",
    "        end = start + batch_size\n",
    "        n = data.shape[0]\n",
    "        while True:\n",
    "            X_batch_old, y_batch = data[start:end], labels[start:end]\n",
    "            X_batch = []\n",
    "            for i in range(X_batch_old.shape[0]):\n",
    "                img = resize(X_batch_old[i, ...], size)\n",
    "                X_batch.append(img)\n",
    "\n",
    "            X_batch = np.array(X_batch)\n",
    "            start += batch_size\n",
    "            end += batch_size\n",
    "            if start >= n:\n",
    "                start = 0\n",
    "                end = batch_size\n",
    "\n",
    "            yield (X_batch, y_batch)\n",
    "    return _f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "\n",
    "Before you try feature extraction on pretrained models it's a good idea to take a moment and run the classifier you used in the Traffic Sign project on the Cifar10 dataset. Cifar10 images are also (32, 32, 3) so the only thing you'll need to change is the number of classes to 10 instead of 43.\n",
    "\n",
    "Cool, now you have something to compare the Cifar10 feature extraction results with!\n",
    "\n",
    "Keep in mind the following as you experiment:\n",
    "\n",
    "_Does feature extraction outperform the Traffic Signs classifier on the Cifar10 dataset? Why?_\n",
    "\n",
    "_Does feature extraction outperform the Traffic Signs classifier on the Traffic Signs dataset? Why?_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load and preprocess data\n",
    "X_train, y_train, X_test, y_test = load_cifar10()\n",
    "# X_train, y_train, X_test, y_test = load_traffic()\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# 0-255 -> 0-1\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# constants\n",
    "nb_epochs = 3\n",
    "batch_size = 32\n",
    "nb_classes = 10 # NOTE: change this to 43 if using traffic sign data\n",
    "\n",
    "# define model\n",
    "input_tensor = Input(shape=(224, 224, 3))\n",
    "\n",
    "# NOTE: It will take a while on the first use since Keras will download the weights for the model\n",
    "# pretrained_model = VGG16(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
    "# pretrained_model = InceptionV3(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
    "pretrained_model = ResNet50(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
    "\n",
    "# NOTE: feel free to change this\n",
    "x = pretrained_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(nb_classes, activation='softmax')(x)\n",
    "model = Model(pretrained_model.input, x)\n",
    "\n",
    "# freeze pretrained model layers\n",
    "for layer in pretrained_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train the model\n",
    "train_gen = gen_and_resize_data(X_train, y_train)\n",
    "test_gen = gen_and_resize_data(X_test, y_test)\n",
    "model.fit_generator(\n",
    "    train_gen(),\n",
    "    X_train.shape[0],\n",
    "    nb_epoch,\n",
    "    nb_val_samples=X_test.shape[0],\n",
    "    validation_data=test_gen())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <keras.engine.topology.InputLayer object at 0x14f487208>\n",
      "1 <keras.layers.convolutional.ZeroPadding2D object at 0x14f487128>\n",
      "2 <keras.layers.convolutional.Convolution2D object at 0x14f487630>\n",
      "3 <keras.layers.normalization.BatchNormalization object at 0x14f488f28>\n",
      "4 <keras.layers.core.Activation object at 0x154547d30>\n",
      "5 <keras.layers.pooling.MaxPooling2D object at 0x154756828>\n",
      "6 <keras.layers.convolutional.Convolution2D object at 0x14f756fd0>\n",
      "7 <keras.layers.normalization.BatchNormalization object at 0x14f774dd8>\n",
      "8 <keras.layers.core.Activation object at 0x14f949630>\n",
      "9 <keras.layers.convolutional.Convolution2D object at 0x14ad00f60>\n",
      "10 <keras.layers.normalization.BatchNormalization object at 0x14ad29e80>\n",
      "11 <keras.layers.core.Activation object at 0x14ad46668>\n",
      "12 <keras.layers.convolutional.Convolution2D object at 0x14ad4bda0>\n",
      "13 <keras.layers.convolutional.Convolution2D object at 0x14af37978>\n",
      "14 <keras.layers.normalization.BatchNormalization object at 0x14af0ff28>\n",
      "15 <keras.layers.normalization.BatchNormalization object at 0x14afe0eb8>\n",
      "16 <keras.engine.topology.Merge object at 0x14f963c88>\n",
      "17 <keras.layers.core.Activation object at 0x14f963c18>\n",
      "18 <keras.layers.convolutional.Convolution2D object at 0x14f5d3dd8>\n",
      "19 <keras.layers.normalization.BatchNormalization object at 0x14f4a6d30>\n",
      "20 <keras.layers.core.Activation object at 0x14f7b5828>\n",
      "21 <keras.layers.convolutional.Convolution2D object at 0x11cdc4b00>\n",
      "22 <keras.layers.normalization.BatchNormalization object at 0x14f7c1f60>\n",
      "23 <keras.layers.core.Activation object at 0x11cbd16d8>\n",
      "24 <keras.layers.convolutional.Convolution2D object at 0x11cb68a20>\n",
      "25 <keras.layers.normalization.BatchNormalization object at 0x1043ccfd0>\n",
      "26 <keras.engine.topology.Merge object at 0x10445b780>\n",
      "27 <keras.layers.core.Activation object at 0x1043fa6d8>\n",
      "28 <keras.layers.convolutional.Convolution2D object at 0x1043fa7f0>\n",
      "29 <keras.layers.normalization.BatchNormalization object at 0x10360e6d8>\n",
      "30 <keras.layers.core.Activation object at 0x103628668>\n",
      "31 <keras.layers.convolutional.Convolution2D object at 0x103635b38>\n",
      "32 <keras.layers.normalization.BatchNormalization object at 0x11facc358>\n",
      "33 <keras.layers.core.Activation object at 0x14f4b9f60>\n",
      "34 <keras.layers.convolutional.Convolution2D object at 0x14f4e1978>\n",
      "35 <keras.layers.normalization.BatchNormalization object at 0x11f8bb518>\n",
      "36 <keras.engine.topology.Merge object at 0x11fa589e8>\n",
      "37 <keras.layers.core.Activation object at 0x11fa58160>\n",
      "38 <keras.layers.convolutional.Convolution2D object at 0x11f8d8198>\n",
      "39 <keras.layers.normalization.BatchNormalization object at 0x11cd477b8>\n",
      "40 <keras.layers.core.Activation object at 0x11cd579e8>\n",
      "41 <keras.layers.convolutional.Convolution2D object at 0x11cd57dd8>\n",
      "42 <keras.layers.normalization.BatchNormalization object at 0x14f8d0860>\n",
      "43 <keras.layers.core.Activation object at 0x14f8e3c88>\n",
      "44 <keras.layers.convolutional.Convolution2D object at 0x14f8e3cf8>\n",
      "45 <keras.layers.convolutional.Convolution2D object at 0x14fb7e358>\n",
      "46 <keras.layers.normalization.BatchNormalization object at 0x14fa60b70>\n",
      "47 <keras.layers.normalization.BatchNormalization object at 0x150099f60>\n",
      "48 <keras.engine.topology.Merge object at 0x150142cc0>\n",
      "49 <keras.layers.core.Activation object at 0x150142438>\n",
      "50 <keras.layers.convolutional.Convolution2D object at 0x150273f28>\n",
      "51 <keras.layers.normalization.BatchNormalization object at 0x15027ebe0>\n",
      "52 <keras.layers.core.Activation object at 0x1502a6f60>\n",
      "53 <keras.layers.convolutional.Convolution2D object at 0x1502ec278>\n",
      "54 <keras.layers.normalization.BatchNormalization object at 0x15039bdd8>\n",
      "55 <keras.layers.core.Activation object at 0x1503e8e10>\n",
      "56 <keras.layers.convolutional.Convolution2D object at 0x1503c0550>\n",
      "57 <keras.layers.normalization.BatchNormalization object at 0x150556f98>\n",
      "58 <keras.engine.topology.Merge object at 0x15055b4a8>\n",
      "59 <keras.layers.core.Activation object at 0x150ed1ba8>\n",
      "60 <keras.layers.convolutional.Convolution2D object at 0x150ed1438>\n",
      "61 <keras.layers.normalization.BatchNormalization object at 0x150f9bcc0>\n",
      "62 <keras.layers.core.Activation object at 0x150a687b8>\n",
      "63 <keras.layers.convolutional.Convolution2D object at 0x150a36f60>\n",
      "64 <keras.layers.normalization.BatchNormalization object at 0x150b00390>\n",
      "65 <keras.layers.core.Activation object at 0x150b61a90>\n",
      "66 <keras.layers.convolutional.Convolution2D object at 0x150b31470>\n",
      "67 <keras.layers.normalization.BatchNormalization object at 0x11ed1e518>\n",
      "68 <keras.engine.topology.Merge object at 0x151721c88>\n",
      "69 <keras.layers.core.Activation object at 0x11ed39400>\n",
      "70 <keras.layers.convolutional.Convolution2D object at 0x11ed39ef0>\n",
      "71 <keras.layers.normalization.BatchNormalization object at 0x151741d68>\n",
      "72 <keras.layers.core.Activation object at 0x1516ecda0>\n",
      "73 <keras.layers.convolutional.Convolution2D object at 0x150d9ef28>\n",
      "74 <keras.layers.normalization.BatchNormalization object at 0x11ed98630>\n",
      "75 <keras.layers.core.Activation object at 0x15138fda0>\n",
      "76 <keras.layers.convolutional.Convolution2D object at 0x15138fd30>\n",
      "77 <keras.layers.normalization.BatchNormalization object at 0x151367860>\n",
      "78 <keras.engine.topology.Merge object at 0x151620978>\n",
      "79 <keras.layers.core.Activation object at 0x151620400>\n",
      "80 <keras.layers.convolutional.Convolution2D object at 0x151489f28>\n",
      "81 <keras.layers.normalization.BatchNormalization object at 0x151495be0>\n",
      "82 <keras.layers.core.Activation object at 0x151ca7da0>\n",
      "83 <keras.layers.convolutional.Convolution2D object at 0x151c03898>\n",
      "84 <keras.layers.normalization.BatchNormalization object at 0x151c2cb38>\n",
      "85 <keras.layers.core.Activation object at 0x1520a5e10>\n",
      "86 <keras.layers.convolutional.Convolution2D object at 0x151c56550>\n",
      "87 <keras.layers.convolutional.Convolution2D object at 0x152d5da58>\n",
      "88 <keras.layers.normalization.BatchNormalization object at 0x152029f98>\n",
      "89 <keras.layers.normalization.BatchNormalization object at 0x1520f4668>\n",
      "90 <keras.engine.topology.Merge object at 0x1521ef0f0>\n",
      "91 <keras.layers.core.Activation object at 0x1521efa20>\n",
      "92 <keras.layers.convolutional.Convolution2D object at 0x152107ef0>\n",
      "93 <keras.layers.normalization.BatchNormalization object at 0x152d85b00>\n",
      "94 <keras.layers.core.Activation object at 0x152dd9d68>\n",
      "95 <keras.layers.convolutional.Convolution2D object at 0x152dd9dd8>\n",
      "96 <keras.layers.normalization.BatchNormalization object at 0x152f77550>\n",
      "97 <keras.layers.core.Activation object at 0x153272f60>\n",
      "98 <keras.layers.convolutional.Convolution2D object at 0x153272e10>\n",
      "99 <keras.layers.normalization.BatchNormalization object at 0x15385f710>\n",
      "100 <keras.engine.topology.Merge object at 0x15373b630>\n",
      "101 <keras.layers.core.Activation object at 0x15373b470>\n",
      "102 <keras.layers.convolutional.Convolution2D object at 0x153cddf98>\n",
      "103 <keras.layers.normalization.BatchNormalization object at 0x153884b70>\n",
      "104 <keras.layers.core.Activation object at 0x153c83f60>\n",
      "105 <keras.layers.convolutional.Convolution2D object at 0x153c79dd8>\n",
      "106 <keras.layers.normalization.BatchNormalization object at 0x153f5f9e8>\n",
      "107 <keras.layers.core.Activation object at 0x15424bcc0>\n",
      "108 <keras.layers.convolutional.Convolution2D object at 0x151663e80>\n",
      "109 <keras.layers.normalization.BatchNormalization object at 0x154048c18>\n",
      "110 <keras.engine.topology.Merge object at 0x154064978>\n",
      "111 <keras.layers.core.Activation object at 0x1542f7550>\n",
      "112 <keras.layers.convolutional.Convolution2D object at 0x1542f74a8>\n",
      "113 <keras.layers.normalization.BatchNormalization object at 0x151be5f28>\n",
      "114 <keras.layers.core.Activation object at 0x154289d30>\n",
      "115 <keras.layers.convolutional.Convolution2D object at 0x15434ad30>\n",
      "116 <keras.layers.normalization.BatchNormalization object at 0x1542a9400>\n",
      "117 <keras.layers.core.Activation object at 0x1544e59b0>\n",
      "118 <keras.layers.convolutional.Convolution2D object at 0x1544e5e10>\n",
      "119 <keras.layers.normalization.BatchNormalization object at 0x153fcb4a8>\n",
      "120 <keras.engine.topology.Merge object at 0x1545930f0>\n",
      "121 <keras.layers.core.Activation object at 0x154593a20>\n",
      "122 <keras.layers.convolutional.Convolution2D object at 0x153fde7f0>\n",
      "123 <keras.layers.normalization.BatchNormalization object at 0x154e31b00>\n",
      "124 <keras.layers.core.Activation object at 0x154375d68>\n",
      "125 <keras.layers.convolutional.Convolution2D object at 0x154375dd8>\n",
      "126 <keras.layers.normalization.BatchNormalization object at 0x155bce550>\n",
      "127 <keras.layers.core.Activation object at 0x154788f60>\n",
      "128 <keras.layers.convolutional.Convolution2D object at 0x154788e10>\n",
      "129 <keras.layers.normalization.BatchNormalization object at 0x1559a1710>\n",
      "130 <keras.engine.topology.Merge object at 0x149150630>\n",
      "131 <keras.layers.core.Activation object at 0x149150470>\n",
      "132 <keras.layers.convolutional.Convolution2D object at 0x1552e3f98>\n",
      "133 <keras.layers.normalization.BatchNormalization object at 0x15530cb70>\n",
      "134 <keras.layers.core.Activation object at 0x15568df60>\n",
      "135 <keras.layers.convolutional.Convolution2D object at 0x15513ddd8>\n",
      "136 <keras.layers.normalization.BatchNormalization object at 0x1557539e8>\n",
      "137 <keras.layers.core.Activation object at 0x1558b3cc0>\n",
      "138 <keras.layers.convolutional.Convolution2D object at 0x15595ee80>\n",
      "139 <keras.layers.normalization.BatchNormalization object at 0x155b25c18>\n",
      "140 <keras.engine.topology.Merge object at 0x155b40898>\n",
      "141 <keras.layers.core.Activation object at 0x155650550>\n",
      "142 <keras.layers.convolutional.Convolution2D object at 0x1556504a8>\n",
      "143 <keras.layers.normalization.BatchNormalization object at 0x15686cf28>\n",
      "144 <keras.layers.core.Activation object at 0x1568d9d30>\n",
      "145 <keras.layers.convolutional.Convolution2D object at 0x156897d30>\n",
      "146 <keras.layers.normalization.BatchNormalization object at 0x1568f9400>\n",
      "147 <keras.layers.core.Activation object at 0x1570779b0>\n",
      "148 <keras.layers.convolutional.Convolution2D object at 0x157077e10>\n",
      "149 <keras.layers.convolutional.Convolution2D object at 0x1579d4080>\n",
      "150 <keras.layers.normalization.BatchNormalization object at 0x1576374a8>\n",
      "151 <keras.layers.normalization.BatchNormalization object at 0x1579af7f0>\n",
      "152 <keras.engine.topology.Merge object at 0x15764b780>\n",
      "153 <keras.layers.core.Activation object at 0x14df78908>\n",
      "154 <keras.layers.convolutional.Convolution2D object at 0x14df78438>\n",
      "155 <keras.layers.normalization.BatchNormalization object at 0x15767f518>\n",
      "156 <keras.layers.core.Activation object at 0x14df228d0>\n",
      "157 <keras.layers.convolutional.Convolution2D object at 0x15766c160>\n",
      "158 <keras.layers.normalization.BatchNormalization object at 0x156825278>\n",
      "159 <keras.layers.core.Activation object at 0x157d32be0>\n",
      "160 <keras.layers.convolutional.Convolution2D object at 0x1576b0d30>\n",
      "161 <keras.layers.normalization.BatchNormalization object at 0x157dd54a8>\n",
      "162 <keras.engine.topology.Merge object at 0x157cb6f98>\n",
      "163 <keras.layers.core.Activation object at 0x1577870f0>\n",
      "164 <keras.layers.convolutional.Convolution2D object at 0x157787a20>\n",
      "165 <keras.layers.normalization.BatchNormalization object at 0x157ce1240>\n",
      "166 <keras.layers.core.Activation object at 0x15791afd0>\n",
      "167 <keras.layers.convolutional.Convolution2D object at 0x15791ac88>\n",
      "168 <keras.layers.normalization.BatchNormalization object at 0x157ed55c0>\n",
      "169 <keras.layers.core.Activation object at 0x157d5ce10>\n",
      "170 <keras.layers.convolutional.Convolution2D object at 0x157d5c710>\n",
      "171 <keras.layers.normalization.BatchNormalization object at 0x157f3e780>\n",
      "172 <keras.engine.topology.Merge object at 0x157adcc88>\n",
      "173 <keras.layers.core.Activation object at 0x157c71e10>\n",
      "174 <keras.layers.pooling.AveragePooling2D object at 0x157c71ef0>\n"
     ]
    }
   ],
   "source": [
    "for i, l in enumerate(pretrained_model.layers):\n",
    "    print(i, l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "By now you should have a good feel for feature extraction and when it might be a good choice. To end this lab, let's summarize when we should consider:\n",
    "\n",
    "1. Feature extraction (train only the top-level of the network, the rest of the network remains fixed)\n",
    "2. Finetuning (train the entire network end-to-end, start with pretrained weights)\n",
    "3. Training from scratch (train the entire network end-to-end, start from random weights)\n",
    "\n",
    "**Consider feature extraction when ...**\n",
    "\n",
    "If dataset is small and similar to the original dataset. The higher-level features learned from the original dataset should be relevant to the new dataset.\n",
    "\n",
    "**Consider finetuning when ...** \n",
    "\n",
    "If the dataset is large and similar to the original dataset. In this case we should be much more confident we won't overfit so it should be safe to alter the original weights.\n",
    "\n",
    "If the dataset is small and very different from the original dataset. You could also make the case for training from scratch. If we choose to finetune it might be a good idea to only use features found earlier on in the network, features found later might be too dataset specific.\n",
    "\n",
    "**Consider training from scratch when ...**\n",
    "\n",
    "If the dataset is large and very different from the original dataset. In this case we have enough data to confidently train from scratch. However, even in this case it might be more beneficial to finetune and the entire network from pretrained weights.\n",
    "\n",
    "---\n",
    "\n",
    "Most importantly, keep in mind for a lot of problems you won't need an architecture as complicated and powerful as VGG, Inception, or ResNet. These architectures were made for the task of classifying thousands of complex classes. A much smaller network might be a much better fit for your problem, especially if you can comfortably train it on moderate hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
